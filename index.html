<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
        "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
    <title>ðŸ”¥ FLAME @ NeurIPS '23</title>

    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap.min.css">
    <link href='https://fonts.googleapis.com/css?family=Lato:400,700' rel='stylesheet' type='text/css'>
    <link href="css/style.css" rel="stylesheet" type="text/css"/>
</head>

<body>

<div class="container">
    <table border="00" align="center">
        <tr>
            <td width="700" align="center" valign="middle">
                <br>
                <span class="title"><strong>ðŸ”¥FLAME<h3 style="display: inline;"> - Foundation Models for AI in Life Sciences and Medicine</h3></strong></span></td>
        </tr>
        <tr>
        <td colspan="3" align="center"><h3>Workshop in planning<br>
<!--        <a href="https://zoom.us/j/95655960109?pwd=U3BNbVJ1M0RLYlBodjM5YThaVFlXZz09">[Zoom Meeting]</a> &nbsp &nbsp &nbsp &nbsp  &nbsp &nbsp &nbsp &nbsp  <a href="https://app.sli.do/event/0iocoe6a">[Ask & Vote Panel Questions]</a>-->
        <strong>
            <br>
            <a href="">[Video Recording]</a>
            <a href="">[Conference Page]</a>
            <a href="">[OpenReview]</a></strong></h3></td>
        </tr>
    </table>
</div>

</br>

<div class="container">
    <h2>Overview</h2>
    <div class="overview">
        <p><br>
        The healthcare industry is a prolific producer of data, with sources ranging from clinical trials data such as electronic health record (EHR) text data, health sensor data, medical imaging, patient-generated data and clinical reports to biomolecular data such as drug-molecule data, metabolomics data, nucleic acid sequences, proteins, gene expression data, and single-cell data. 
        <br><br>
        However, much of these complex data are unstructured, incomplete, inconsistent, prone to errors, and heterogeneous, rendering traditional machine learning models less effective in analyzing it. To overcome such, foundation models (FM) such as large language models enable novel applications using such unstructured data, reducing the need for manual feature engineering or large volumes of unlabeled data for pretraining. Foundation models have the potential to revolutionize the clinical understanding, diagnosis, and treatment of complex medical conditions, while also improving the accuracy, and efficiency of healthcare systems. This technology can rapidly enhance patient outcomes, streamline processes, and reduce costs for healthcare providers and patients alike.
        <br><br>
        Recently, foundation models have been employed in a handful of healthcare tasks such as generating text, creating images from text descriptions, generating captions for images, and utilizing vision-language contrastive learning. Despite early signs of promise, the use of foundation models in healthcare remains largely underexplored and underutilized, limited to a few publicly available medical datasets, which raises concerns about generalization and robustness. Additionally, there is a lack of necessary empirical evidence to support its effectiveness.
        <br><br>
        <h3>Reference</h3>  we <strong>bold</strong> authors that are from FLAME.<br><br>
        [1] Foundation models for generalist medical artificial intelligence, <strong>Michael Moor</strong>, â€¦, & Pranav Rajpurkar, Nature 2023 <br>
        [2] Scientific discovery in the age of artificial intelligence, <strong>Hanchen Wang</strong> â€¦, Yoshua Bengio & Marinka Zitnik, Nature 2023 <br>
        [3] Large language models generate functional protein sequences across diverse families, Madani, A., ... & <strong>Naik, N</strong>, Nature Biotechnology 2023 <br>
        [4] How will generative AI disrupt data science in drug discovery?, Jean-Philippe Vert, Nature Biotechnology 2022 <br>
        [5] Large Language Models Encode Clinical Knowledge, Karan Singhal, â€¦,  <strong>Greg S. Corrado</strong>, â€¦, <strong>Yun Liu</strong>, â€¦, arXiv:2212.13138 <br>
        [6] Towards Expert-Level Medical Question Answering with Large Language Models, K. Singhal, â€¦,  <strong>Y. Liu</strong>, â€¦, <strong>G. Corrado</strong>, ..., arXiv:2305.09617<br>
        [7] Solving quantitative reasoning problems with language models, Aitor Lewkowycz, â€¦, <strong>Behnam Neyshabur</strong>, â€¦, Vedant Misra, NeurIPS 2022<br>
        [8] Training language models with language feedback at scale, J Scheurer, â€¦, A Chen, <strong>K Cho</strong>, E Perez, arXiv:2303.16755 <br>
        [9] Health system-scale language models are all-purpose prediction engines, L. Y Jiang, ..., <strong>Kyunghyun Cho</strong> & Eric K. Oermann , Nature 2023<br>
        [10] Transfer learning enables predictions in network biology, Christina V. Theodoris et al., Nature 2023 <br>
        [11] Using the Veil of Ignorance to align AI systems with principles of justice, Laura Weidinger et al, PNAS 2023 <br>
        [12] Lessons learned from translating AI from development to deployment in healthcare, Kasumi Widner,, ... <strong>Yun Liu</strong>, ..., Nature Medicine 2023<br><br>
    </div>
</div>

</br>

<div class="container">
    <h2>Call for papers</h2>
    <br>
    <div class="overview">
    The workshop invites researchers to submit working papers in the research areas including, but not limited to: </p>
        <ul>
<li>Application of foundation models in drug discovery and development</li>
<li>Predictive modeling for disease diagnosis and prognosis using foundational models</li>
<li>Natural language processing techniques for clinical text mining and EHR analysis</li>
<li>Integration of multi-omics data for precision medicine using AI and machine learning</li>
<li>Explainability and interpretability of foundational models in life sciences and medicine</li>
<li>Transfer learning and domain adaptation with foundational models</li>
<li>Ethical considerations and responsible use of foundational models in healthcare</li>
<li>Benchmarking and evaluation methodologies for foundational models</li>
    </ul>
    All submissions are required to use this style file. References and appendices do not count towards the four-page limit, but reviewers will not be required to read beyond the four pages. All accepted papers will be non-archival. Papers have to be anonymized for review, and submitted through the <a href="">OpenReview</a> portal.<br><br>
    </div>
</div>

</br>

<div class="container">
    <h2>Important dates</h2>
    <br>
    <h3><strong><font color="purple">Under Construction</font></strong></h3>
<!--     <div class="overview">
        <ul>
        <li>Submission portal opens: Jan. 08, 2023</li>
    </ul>
    </div> -->
</div>
</br>

<!-- <div class="container">
    <h2>Awards</h2>
    <div class="schedule">
    <h3><p><strong><font color="#4562c2"><li>Best Paper Award</li></font></strong></p></h3>
    <p><a href="http://openaccess.thecvf.com/content_CVPRW_2020/papers/w47/Gupta_Improving_the_Affordability_of_Robustness_Training_for_DNNs_CVPRW_2020_paper.pdf"><papertitle>Improving the affordability of robustness training for DNNs</papertitle></a>
    <br>Sidharth Gupta (University of Illinois at Urbana-Champaign); Parijat Dube (IBM Research); Ashish Verma (IBM Research)</p>

    <h3><p><strong><font color="#4562c2"><li>Best Presentation</li></font></strong></p></h3>
    <p><a href="short_papers/14.pdf"><papertitle>On Certifying Robustness against Backdoor Attacks via Randomized Smoothing</papertitle></a>
    <font color="purple">Under Construction</font>
    </p>

    <h3><p><strong><font color="#4562c2"><li>Travel Award</li></font></strong></p></h3>
    <p>Tianfu Wu (NC State University)</p>
    <font color="purple">Under Construction</font>
    </div>
</div>
</br> -->

<div class="container">
    <h2>Schedule</h2><br>
    <h3><strong><font color="purple">Under Construction</font></strong></h3>
<!--     <div class="schedule">
        <p><strong>09:00 - 09:10 &nbsp &nbsp &nbsp &nbsp Opening Remark </strong></p>        
    </div> -->
</div>

<!--</br>-->
<!--<div class="container">-->
<!--    <h2>Call For Papers</h2>-->
<!--    <div class="call4papers">-->
<!--      <p><font color="red">We recently received many inquiries about the ddl extension for the paper submission, due to the inconvenience brought by the breakout of COVID-19. We understand this hard situation for all researchers, and decide to allow 1 more week for the paper submission. This deadline is firm and will not be extended futher. If you need any other accommodations, please let us know and we will try our best to help.</font></p>-->-->
<!--        <p><strong>Submission server</strong>: <a href="https://cmt3.research.microsoft.com/CVPRamlcv2020">https://cmt3.research.microsoft.com/CVPRamlcv2020</a></p>-->
<!--        <p><strong>Submission format</strong>: Submissions need to be <strong>anonymized</strong>, and follow the <a href="http://cvpr2020.thecvf.com/submission/main-conference/author-guidelines">CVPR 2020 Submission Guidelines</a>. The workshop considers two types of submissions: (1) <font color="orange"><strong>Long Paper</strong></font>: the page limitation is eight excluding references, and will be included in the official CVPR proceedings; (2) <font color="orange"><strong>Extended Abstract</strong></font>: the page limitation is four excluding references, and will <strong>NOT</strong> be included in the official CVPR proceedings. Based on the PCâ€™s recommendation, the accepted long paper/extended abstract will be allocated either a contributed talk or a poster presentation.</p>-->
<!--        -->
<!--        <p>We invite submissions on <strong>any aspect of adversarial machine learning in computer vision</strong>. This includes, but is not limited to:</p>-->
<!--        <ul>-->
<!--            <li>Adversarial attacks on computer vision models in the digital/physical world</li>-->
<!--            <li>Improving model robustness against adversarial attacks</li>-->
<!--            <li>Theoretical understanding of adversarial machine learning</li>-->
<!--            <li>Applying adversarial machine learning to diagnosing/explaining computer vision models</li>-->
<!--            <li>Improving representation learning via adversarial machine learning </li>-->
<!--            <li>Applications of adversarial machine learning in computer vision tasks (e.g., generative models, image captioning, image recognition)</li>-->
<!--        </ul>-->
<!--        -->
<!--        <p><font color="red">We are excited to announce a <strong>DeepMind Best Paper Award and travel grants</strong>. The workshop is fully sponsored by DeepMind through the University of Oxford.</font></p>-->
<!--        <ul>-->
<!--            <li>The best paper award will be selected from long papers only. The winner will receive the <strong>US$ 1,500 prize and a certificate</strong> at the workshopâ€™s closing.</li>-->
<!--            <li>The workshop has several travel grants (US$100 ~ $200 each) for authors. The travel grants will be considered especially for those from underrepresented groups, such as women and minority ethnic groups.</li>-->
<!--        </ul>-->
<!--    </div>-->
<!--</div>-->
</br>

<div class="container">
    <h2>Confirmed speakers and panelists</h2>
   <h3><font color="purple"><strong>All will be in person</strong></font></h3><br>
    <div>
        <div class="instructor">
            <a href="https://www.vanderschaar-lab.com/">
                <div class="instructorphoto"><img src="figures/Mihaela.jpeg"></div>
                <div>Mihaela van der Schaar<br>University of Cambridge</div>
            </a>
        </div>

<!--         <div class="instructor">
            <a href="https://gsk.ai/working-with-us/">
                <div class="instructorphoto"><img src="figures/KimBranson.jpg"></div>
                <div>Kim Branson<br>GSK</div>
            </a>
        </div> -->

        <div class="instructor">
            <a href="https://imes.mit.edu/people/celi-leo">
                <div class="instructorphoto"><img src="figures/LeoCeli.jpg"></div>
                <div>Leo Celi <br>Harvard/MIT</div>
            </a>
        </div>

        <div class="instructor">
            <a href="https://www.gichoya.me/">
                <div class="instructorphoto"><img src="figures/judy-gichoya.jpeg"></div>
                <div>Judy Wawira Gichoya<br>Emory University</div>
            </a>
        </div>

        <div class="instructor">
            <a href="https://research.google/people/GregCorrado/">
                <div class="instructorphoto"><img src="figures/GregCorrado.png"></div>
                <div>Greg Corrado<br>Google</div>
            </a>
        </div>
    </div>

    <p></p>
    <br>
    <div>
        <div class="instructor">
            <a href="https://en.wikipedia.org/wiki/Daphne_Koller">
                <div class="instructorphoto"><img src="figures/DaphneKoller.jpeg"></div>
                <div>Daphne Koller<br>Insitro</div>
            </a>
        </div>

        <div class="instructor">
            <a href="https://www.nature.com/nature/editors">
                <div class="instructorphoto"><img src="figures/Yann-Sweeney.jpg"></div>
                <div>Yann Sweeney<br>Nature</div>
            </a>
        </div>
        
<!--         <div class="instructor">
            <a href="https://scholar.google.com/citations?user=oflcSSoAAAAJ&hl=en">
                <div class="instructorphoto"><img src="figures/JohnMarioni.jpg"></div>
                <div>John Marioni<br>Genentech; EMBL-EBI</div>
            </a>
        </div>
        <div class="instructor">
            <a href="https://web.mit.edu/naik/www/">
                <div class="instructorphoto"><img src="figures/NikhilNaik.jpeg"></div>
                <div>Nikhil Naik <br>Salesforce</div>
            </a>
        </div>  -->
        <div class="instructor">
            <a href="https://www.bunne.ch/">
                <div class="instructorphoto"><img src="figures/bunnech.jpeg"></div>
                <div>Charlotte Bunne<br>ETH Zurich</div>
            </a>
        </div>

    </div>

        <p></p>
    <br>
    <div>
        <div class="instructor">
            <a href="https://www.helmholtz-munich.de/en/icb/pi/fabian-theis">
                <div class="instructorphoto"><img src="figures/fabian_theis.jpeg"></div>
                <div>Fabian Theis<br>Helmholtz Munich</div>
            </a>
        </div>
        
        <div class="instructor">
            <a href="https://www.gene.com/scientists/our-scientists/aviv-regev">
                <div class="instructorphoto"><img src="figures/avivregev.jpg"></div>
                <div>Aviv Regev<br>Genentech; MIT</div>
            </a>
        </div>


<!--         <div class="instructor">
            <a href="https://web.mit.edu/naik/www/">
                <div class="instructorphoto"><img src="figures/NikhilNaik.jpeg"></div>
                <div>Nikhil Naik <br>Salesforce</div>
            </a>
        </div> -->
    </div>
</div>

<div class="container">
    <h2>Organising committee</h2><br>
    <div>
        <div class="instructor">
            <a href="https://kyunghyuncho.me">
                <div class="instructorphoto"><img src="figures/KC.jpg"></div>
                <div>Kyunghyun Cho<br>NYU; Prescient Design</div>
            </a>
        </div>

        <div class="instructor">
            <a href="https://www.linkedin.com/in/mohsen-hejrati/">
                <div class="instructorphoto"><img src="figures/Mohsen.jpeg"></div>
                <div>Mohsen Hejrati<br>Genentech</div>
            </a>
        </div>

        <div class="instructor">
            <a href="https://www.neyshabur.net">
                <div class="instructorphoto"><img src="figures/BehnamNeyshabur.jpeg"></div>
                <div>Behnam Neyshabur<br>DeepMind</div>
            </a>
        </div>

        <div class="instructor">
            <a href="https://research.google/people/105698/">
                <div class="instructorphoto"><img src="figures/YunLiu.jpeg"></div>
                <div>Yun Liu<br>Google</div>
            </a>
        </div>
    </div>

    <p></p>
    <br>
    <div>

        <div class="instructor">
            <a href="https://www.linkedin.com/in/somaye-hashemifar-65967357">
                <div class="instructorphoto"><img src="figures/SomayeHashemifar.jpeg"></div>
                <div>Somaye Hashemifar<br>Genentech</div>
            </a>
        </div>

        <div class="instructor">
            <a href="https://haleakrami.github.io/">
                <div class="instructorphoto"><img src="figures/haleh.jpeg"></div>
                <div>Haleh Akrami<br>USC</div>
            </a>
        </div>


        <div class="instructor">
            <a href="https://www.linkedin.com/in/changlin-wan-965442108/">
                <div class="instructorphoto"><img src="figures/changlinwan.jpeg"></div>
                <div>Changlin Wan<br>Genentech</div>
            </a>
        </div>

        <div class="instructor">
            <a href="https://yuedong.us/">
                <div class="instructorphoto"><img src="figures/yue_dong.jpeg"></div>
                <div>Yue Dong<br>UC Riverside</div>
            </a>
        </div> 
    </div>

    <p></p>
    <br>
    <div>
         <div class="instructor">
            <a href="https://www.hanchenw.com">
                <div class="instructorphoto"><img src="figures/hanchenwang.png"></div>
                <div>Hanchen Wang<br>Genentech; Stanford</div>
            </a>
        </div>

         <div class="instructor">
            <a href="https://www.linkedin.com/in/ciriondo/">
                <div class="instructorphoto"><img src="figures/claudia.jpeg"></div>
                <div>Claudia Iriondo<br>Genentech</div>
            </a>
        </div>
        
         <div class="instructor">
            <a href="https://www.linkedin.com/in/michael-moor/">
                <div class="instructorphoto"><img src="figures/michaelmoor.jpeg"></div>
                <div>Michael Moor<br>Stanford</div>
            </a>
        </div>
    </div>
</div>
</br>
</br>

<div class="container">
    <h2>Program committee</h2>
    <br>
    <h3><font color="purple"><strike>We are now actively looking for reviewers/PCs, if you are interested, please fill out this 
        <a href="">Google form</a>!</strike></font></h3>
<!--     <div class="pcs-row pcs">
        <div class="pcs-column">
            <ul>
                <li>Benjamin Chidester (CMU)</li>
                <li>Romain Lopez (Stanford, GenenTech)</li>
            </ul>
        </div>
        <div class="pcs-column">
            <ul>
                <li>Mariano Gabitto (UW)</li>
                <li>Kemal Inecik (Helmholtz Munich)</li>
            </ul>
        </div>
    <div class="pcs-column">
            <ul>
                <li>Gao Xin (KAUST)</li>
                <li>Lior Pachter (Caltech)</li>
            </ul>
        </div>
    </div> -->
</div>

</br>
<div class="container">
<h2>Accepted papers</h2><br>
<h3><strong><font color="purple">Under Construction</font></strong></h3>
<!-- <div class="schedule">
<p><a href=""><papertitle>Machine learning-assisted close-set X-ray diffraction phase identification of transition metals</papertitle></a>
        <br>Maksim Zhdanov; Andrey Zhdanov</p>
    
        <p><a href=""><papertitle>Constructing and Compressing Global Moment Descriptors from Local Atomic Environments</papertitle></a>
        <br>Vahe Gharakhanyan; Max Shirokawa Aalto; Aminah Alsoulah; Nongnuch Artrith; Alexander Urban</p>
</div> -->
</div>

</br>
<div class="container">
    <h2>Contact</h2><br>
    <h3><strong><font color="purple">Under Construction</font></strong></h3>
<!--     <br>
    <h3>If you have any questions, you can reach out to organizers via ...</h3> -->
</div>
</br>

<div class="container">
    <h2>Sponsor</h2><br>
    <h3><strong><font color="purple">Under Construction</font></strong></h3>
    <!-- <div><img width="300" src="figures/msr.jpeg"></div><br> -->
</div>
</br>

<div class="containersmall">
        The webpage template is by the courtesy of <a href="https://adv-workshop-2020.github.io/">CVPR 2020 Workshop on Adversarial Machine Learning in Computer Vision</a>.
    </p>
</div>
</br>
</br>
<!--<p align="center" class="acknowledgement">Last updated: Jan. 6, 2017</p>-->
</body>
</html>
